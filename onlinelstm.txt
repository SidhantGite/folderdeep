# ------------------------------------------------------------
# IMDB Sentiment Classification using LSTM (Local Save + Load)
# ------------------------------------------------------------

import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt
import os

print("âœ… TensorFlow version:", tf.__version__)

# ------------------------------------------------------------
# Step 1: Download & Save IMDB Dataset Locally
# ------------------------------------------------------------
num_words = 10000
maxlen = 200
save_path = "./imdb_data.npz"

if not os.path.exists(save_path):
    print("ğŸ“¥ Downloading IMDB dataset...")
    (X_train, y_train), (X_test, y_test) = keras.datasets.imdb.load_data(num_words=num_words)
    np.savez_compressed(save_path, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test)
    print(f"âœ… Dataset downloaded and saved as {save_path}")
else:
    print(f"ğŸ“‚ Found local dataset at {save_path}. Loading...")

# ------------------------------------------------------------
# Step 2: Load IMDB Dataset from Local File
# ------------------------------------------------------------
data = np.load(save_path, allow_pickle=True)
X_train, y_train = data["X_train"], data["y_train"]
X_test, y_test = data["X_test"], data["y_test"]

# ------------------------------------------------------------
# Step 3: Preprocess (Pad Sequences)
# ------------------------------------------------------------
X_train = keras.preprocessing.sequence.pad_sequences(X_train, maxlen=maxlen)
X_test = keras.preprocessing.sequence.pad_sequences(X_test, maxlen=maxlen)

print(f"Training data shape: {X_train.shape}")
print(f"Test data shape: {X_test.shape}")

# ------------------------------------------------------------
# Step 4: Build LSTM Model
# ------------------------------------------------------------
model = keras.Sequential([
    layers.Embedding(num_words, 128, input_length=maxlen),
    layers.LSTM(128),
    layers.Dense(1, activation='sigmoid')
])

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
model.summary()

# ------------------------------------------------------------
# Step 5: Train the Model
# ------------------------------------------------------------
history = model.fit(
    X_train, y_train,
    validation_split=0.2,
    epochs=5,
    batch_size=128,
    verbose=1
)

# ------------------------------------------------------------
# Step 6: Plot Accuracy and Loss
# ------------------------------------------------------------
plt.figure(figsize=(10,4))

plt.subplot(1,2,1)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title("Loss Curve")
plt.xlabel("Epochs"); plt.ylabel("Loss")
plt.legend()

plt.subplot(1,2,2)
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.title("Accuracy Curve")
plt.xlabel("Epochs"); plt.ylabel("Accuracy")
plt.legend()

plt.show()

# ------------------------------------------------------------
# Step 7: Evaluate Model
# ------------------------------------------------------------
test_loss, test_acc = model.evaluate(X_test, y_test, verbose=1)
print(f"\nâœ… Test Accuracy: {test_acc:.4f}")

# ------------------------------------------------------------
# Step 8: Predict on Sample Reviews
# ------------------------------------------------------------
pred = (model.predict(X_test[:5]) > 0.5).astype(int)

print("\nğŸ¯ Sample Predictions:\n")
for i in range(5):
    print(f"Review #{i}")
    print("Actual:", y_test[i], "| Predicted:", int(pred[i]))
    print("-----------------------------")

print(f"\nğŸ“ Dataset location: {os.path.abspath(save_path)}")
